AI (Artificial Intelligence)
============================

* The elephant in the room in many education settings.
* Mass public misunderstanding
* TODO this section needs fleshing out MASSIVELY!

https://experiments.withgoogle.com/collection/ai
https://machinelearningforkids.co.uk/
https://teachablemachine.withgoogle.com/

https://www.appsforgood.org/courses/machine-learning

* [Summary of Envisioning AI for K-12: What should every child know about AI?](https://blog.teachcomputing.org/summary-of-what-should-every-child-know-about-ai/)

radiologists move to differnt hospital - ai cant be transfered

* [Coding Challenge #158: Shape Classifier Neural Network with ml5.js](https://www.youtube.com/watch?v=3MqJzMvHE3E) Coding Train 36min
    * He trains a network himself with drawing shapes and it recognises shapes drawn on paper!
    * This could be an AMAZING activity
        * What about training the algorithm with lines - and then trying to recognise a filled circle. Could this be a powerful lesson in the data we tain algorithms with? (like the issues big tech companies had with recognising black faces with login systems)

* [DeepMind: Generally capable agents emerge from open-ended play](https://deepmind.com/blog/article/generally-capable-agents-emerge-from-open-ended-play)
    * Beautiful visual description of general purpose game playing AI.
    * _Tasks_ for the AI to overcome are created procedurally

* [Explaining Machine Learning Predictions](https://explainml-tutorial.github.io/) - State-of-the-art, Challenges, and Opportunities
    * [Explainable Machine Learning: Understanding the Limits & Pushing the Boundaries](https://drive.google.com/file/d/1xn2dCDAeEEhB_rex202KxMPqIPj31fZ4/view) Hima Lakkaraju


* [Machine Learning: The Great Stagnation](https://marksaroufim.substack.com/p/machine-learning-the-great-stagnation)
    * (I need to read up on AI and matrix's in general)
    * The writer talks about AI research in general stagnating - there are some interesting AI research out there

* [What I Wish Someone Had Told Me About Tensor Computation Libraries](https://eigenfoo.xyz/tensor-computation-libraries/)

* [Introduction to Reinforcement Learning with David Silver](https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver)
    * Explore the concepts and methods used in modern reinforcement learning research.
    * 10 part course

* [Uppestcase and Lowestcase Letters](http://tom7.org/lowercase/) 12min
    * Using [[ai]] to find the uppercase of an uppercase letter and the lowercase of a lowercase letter.
    * Some really ugly font output
    * Really well described video

* [Ai mid 2021. Self driving car meets reality](https://blog.piekniewski.info/2021/05/12/ai-mid-2021/)
    * Size of dataset. In one city it works. It wont work across the world with different vehicles and terrain
    * AI better than radiologists ... but move it the hospital down the road, with slightly different imaging and it  wont work and needs to be retrained from scratch, where as a radiologist can just walk down the road.


---


[Blockgeni Education](https://blockgeni.com/) - AI, Blockchain, DataScience, Crypto engineering

[World Models](https://adgefficiency.com/world-models/) - AI paper to teach 2d car how to drive

* [MarIO](https://www.youtube.com/watch?v=qv6UVOQ0F44) - AI plays Super Mario World
* [learnfun & playfun: A general technique for automating NES games](http://tom7.org/mario/)

[Open Source Tools & Data for Music Source Separation](https://source-separation.github.io/tutorial/landing.html)

* [Self-Organising Textures](https://distill.pub/selforg/2021/textures/)
    * Neural Cellular Automata Model of Pattern Formation
    * Growing textures


[The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)

AI is made by men (??!?)

* [Google Search: Race bias in algorithms](https://www.google.com/search?q=race+bias+in+algorithms)
* [Data scientist Cathy O’Neil on the cold destructiveness of big data](https://qz.com/819245/data-scientist-cathy-oneil-on-the-cold-destructiveness-of-big-data/)

* [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)
    * trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.
    * _Avocado Chair_
    * _a stained glass window with an image of a blue strawberry_

* Stanford AI Lab Blog: [An Introduction to Knowledge Graphs](http://ai.stanford.edu/blog/introduction-to-knowledge-graphs/)

Services
--------



* [base64.ai](https://base64.ai/)
    * Extract text, photos, and signatures from all document types
    * No more manual data entry
    * [[automation]]


Recruitment
-----------

[[job-applications]]

* [The computers rejecting your job application](https://www.bbc.co.uk/news/business-55932977)
    * Frankly, it was a little stressful to know that my application was being judged by a computer and not by a human being.
    * A professional journalist, I had recently applied for a new job, and for the first part of the recruitment process the publisher made me play a number of simple online games from the comfort of my own home. These included having to quickly count the number of dots in two boxes, inflating a balloon before it burst to win money, and matching emotions to facial expressions. 
    * Then an artificial intelligence (AI) software system assessed my personality, and either passed or failed me. No human had a look-in.
    * I wondered: is it fair for a computer alone to accept or reject your job application?

---

* [OpenAI Five Beats World Champion DOTA2 Team 2-0](https://www.youtube.com/watch?v=tfb6aEUMC04)
    * it's not a competition

* [NVIDIA Canvas](https://www.nvidia.com/en-gb/studio/canvas/)
    * From an MSpaint style image, create photorealistic landscapes

* [It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://aclanthology.org/2021.naacl-main.185/)
    * > ... enormous amounts of compute are required for training and applying such big models, resulting in a large carbon footprint and making it difficult for researchers and practitioners to use them. We show that performance similar to GPT-3 can be obtained with language models that are much “greener” in that their parameter count is several orders of magnitude smaller. This is achieved by converting textual inputs into cloze questions that contain a task description, combined with gradient-based optimization; exploiting unlabeled data gives further improvements. ...

[//begin]: # "Autogenerated link references for markdown compatibility"
[ai]: ai.md "AI (Artificial Intelligence)"
[automation]: automation.md "Automation"
[job-applications]: job-applications.md "Job Applications and Interviews"
[//end]: # "Autogenerated link references"